{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba1N9X2IldRj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image, ImageDraw\n",
        "from io import BytesIO\n",
        "import base64\n",
        "\n",
        "# Authentication tokens and URLs for the APIs\n",
        "LLAVA_NEXT_URL = \"https://supplement-convenient-scores-forgotten.trycloudflare.com/llava/generate\"\n",
        "LLAVA_NEXT_TOKEN = \"Mklm9M70UL39aQhBLiDSDM2yv1V73uXWMA-GBN1LBDU\"\n",
        "FLUX_URL = \"https://maintained-thai-filter-four.trycloudflare.com/imagine/generate\"\n",
        "FLUX_TOKEN = \"calm-bold-tree-bd1b1c8bc141403231e7f0a8\"\n",
        "SDXL_URL = \"https://singing-shadows-duty-loan.trycloudflare.com/imagine/generate\"\n",
        "SDXL_TOKEN = \"wise-radiant-wave-b77c84b64e9efa2ebf8710ca\"\n",
        "\n",
        "def summarize_story(context):\n",
        "    # Define the token and endpoint\n",
        "    VALID_TOKEN = \"AEulafWZQ1xhIkeLgjcp5nhL7d0cLPWiXAU34DTVvXI\"\n",
        "    url = \"https://cu-vertical-dimensional-continuity.trycloudflare.com/phi3/generate\"\n",
        "    # Set headers\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {VALID_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    # Define payload\n",
        "    payload = {\n",
        "        \"inputs\": \"<|system|>\\nYou are a creative writing assistant who can summarize large sentences in few words. Summarize the given prompt in less than 200 characters.<|end|>\\n<|user|>\\n Prompt is: \"+context+\".<|end|>\\n<|assistant|>\",\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": 300,\n",
        "            \"temperature\": 0.7\n",
        "        }\n",
        "    }\n",
        "    # Make the request\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    # Display the response\n",
        "    if response.status_code == 200:\n",
        "        print(response.json().get(\"generated_text\", \"No response text available\"))\n",
        "    #else:\n",
        "    #    ; #print(f\"Error: {response.status_code}, {response.text}\")\n",
        "    summary=response.json().get(\"generated_text\") #{response.text}\n",
        "    return summary\n",
        "\n",
        "# Function to evaluate if the initial prompt is clear enough\n",
        "def evaluate_prompt(prompt):\n",
        "    if len(prompt.split()) < 10:\n",
        "        return False  # Not enough detail\n",
        "    return True  # Assuming it's detailed enough for now\n",
        "\n",
        "# Function to enhance the prompt if it's not detailed enough\n",
        "def enhance_prompt(prompt):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {LLAVA_NEXT_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"inputs\": f\"<|system|>\\nYou are a creative manga story writer.<|end|>\\n<|user|>\\nThe following prompt is vague. Please enhance the prompt to be detailed enough for an entire story. Prompt: {prompt}\\n<|assistant|>\",\n",
        "        \"parameters\": {\"max_new_tokens\": 150}\n",
        "    }\n",
        "    response = requests.post(LLAVA_NEXT_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"generated_text\", \"\").strip()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return prompt  # If enhancement fails, return original prompt\n",
        "\n",
        "# Function to convert image to base64 encoding\n",
        "def image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
        "\n",
        "# Function to generate story sentence from a prompt using LLava-Next API\n",
        "def generate_story_sentence_llava(prompt, previous_sentence=\"\", previous_image_path=\"\", max_tokens=500):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {LLAVA_NEXT_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    # Convert previous image to base64\n",
        "    print(\"previous_image_path-> \",  previous_image_path)\n",
        "    previous_image_base64 = image_to_base64(previous_image_path) if previous_image_path else \"\"\n",
        "\n",
        "    # Prepare the prompt and the image for the LLava-Next model\n",
        "    input_data = {\n",
        "        \"inputs\": f\"Story Context: {prompt}. \\n Previous sentence: {previous_sentence}\",\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_tokens,  # Limit output to 500 tokens\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.9,\n",
        "        },\n",
        "        \"image\": previous_image_base64,  # Include the base64 encoded previous image for style context\n",
        "        \"instruction\": \"Use the Story Context to maintain global consistency in story creation. Generate next sentence given the Previous sentence, and the previous image. give only one sence\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(LLAVA_NEXT_URL, headers=headers, json=input_data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        #print (response.json().get(\"generated_text\", \"\").strip())\n",
        "        return response.json().get(\"generated_text\", \"\").strip()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to generate story sentence from a prompt using LLava-Next API\n",
        "def generate_story_sentence_only_text_llava(prompt, previous_sentence=\"\", previous_image_path=\"\", max_tokens=500):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {LLAVA_NEXT_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    # Convert previous image to base64\n",
        "    #print(\"previous_image_path \" +  previous_image_path)\n",
        "    previous_image_base64 = image_to_base64(previous_image_path) if previous_image_path else \"\"\n",
        "\n",
        "    # Prepare the prompt and the image for the LLava-Next model\n",
        "    input_data = {\n",
        "        \"inputs\": f\"Story Context: {prompt}. \\n Previous sentence: {previous_sentence}\",\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_tokens,  # Limit output to 500 tokens\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.9,\n",
        "        },\n",
        "        \"instruction\": \"Use the Story Context to maintain global consistency in story creation. Generate next sentence given the prompt and Previous sentence.\"\n",
        "    }\n",
        "\n",
        "    response = requests.post(LLAVA_NEXT_URL, headers=headers, json=input_data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        #print (response.json().get(\"generated_text\", \"\").strip())\n",
        "        return response.json().get(\"generated_text\", \"\").strip()\n",
        "\n",
        "    else:\n",
        "        print (\"o no\")\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to generate image from text using Flux API\n",
        "def generate_image(description, previous_image_description, output_file):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {FLUX_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    # Combine sentence description with the description of the previous image for context\n",
        "    combined_description = f\"{description}. Previous Image: {previous_image_description}\"\n",
        "    payload = {\n",
        "        \"prompt\": combined_description[:200],  # Max 200 characters for prompt\n",
        "        \"img_size\": 512,\n",
        "        \"guidance_scale\": 7.5,\n",
        "        \"num_inference_steps\": 50,\n",
        "        \"seed\":  101,\n",
        "    }\n",
        "    response = requests.post(FLUX_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        with open(output_file, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"Image saved to {output_file}\")\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "\n",
        "# Function to generate image using SDXL API for higher resolution\n",
        "def generate_sdxl_image(description, previous_image_description, output_file):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {SDXL_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    # Combine sentence description with the description of the previous image for context\n",
        "    combined_description = f\"{description}. #Previous Image: {previous_image_description}\"\n",
        "    payload = {\n",
        "        \"prompt\": combined_description[:200],  # Max 200 characters for prompt\n",
        "        \"img_size\": 1024,\n",
        "        \"guidance_scale\": 7.5,\n",
        "        \"num_inference_steps\": 50,\n",
        "        \"seed\":  101,\n",
        "    }\n",
        "    response = requests.post(SDXL_URL, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        with open(output_file, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"Image saved to {output_file}\")\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "\n",
        "# Function to stitch images and text together into a final manga page\n",
        "def stitch_images_and_text(images, text, output_file):\n",
        "    print(images)\n",
        "    width = max(img.width for img in images)\n",
        "    height = sum(img.height for img in images)\n",
        "    final_image = Image.new(\"RGB\", (width, height), (255, 255, 255))\n",
        "\n",
        "    y_offset = 0\n",
        "    for i, img in enumerate(images):\n",
        "        final_image.paste(img, (0, y_offset))\n",
        "        y_offset += img.height\n",
        "        text_position = (10, y_offset - 20)\n",
        "        draw = ImageDraw.Draw(final_image)\n",
        "        draw.text(text_position, text[i], fill=(0, 0, 0))\n",
        "\n",
        "    final_image.save(output_file)\n",
        "    print(f\"Final manga saved to {output_file}\")\n",
        "\n",
        "# Main function to generate a manga\n",
        "def create_manga(prompt, max_images= 6, max_tokens=500):\n",
        "    # Step 1: Evaluate the Initial Prompt\n",
        "    if not evaluate_prompt(prompt):\n",
        "        print(\"Prompt is not detailed enough. Enhancing the prompt...\")\n",
        "        prompt = enhance_prompt(prompt)\n",
        "\n",
        "    context = \"\"\n",
        "    images = []\n",
        "    story_text = []\n",
        "    #previous_image_description = \"An empty spaceship with two passengers in cryosleep.\"  # Initial description\n",
        "    previous_image_description = \"A gigantic palace full of monkeys and monkey king.\"  # Initial description\n",
        "\n",
        "    for i in range(max_images):\n",
        "        sentence = None\n",
        "\n",
        "        print (\"iteration to evaluate==================================================================\" , i )\n",
        "\n",
        "        #1st iteration relies on prompt alone\n",
        "        if i == 0:\n",
        "           sentence = generate_story_sentence_only_text_llava(prompt, context, None, max_tokens)\n",
        "        else:\n",
        "           sentence = generate_story_sentence_llava(summarize_story(prompt), summarize_story(context), f\"scene_{i}.png\", max_tokens)\n",
        "\n",
        "        print (\"sentence generated is for =>\",i, sentence)\n",
        "        if not sentence:  # If no sentence is generated, stop\n",
        "            sentence = generate_story_sentence_only_text_llava(prompt, previous_image_description, None, max_tokens)\n",
        "            #break\n",
        "\n",
        "        # Print the sentence associated with each image\n",
        "        print(f\"Sentence {i + 1}: {sentence}\")\n",
        "\n",
        "        # Step 2: Generate Image for the sentence, including context from the previous image\n",
        "        output_image_file = f\"scene_{i + 1}.png\"\n",
        "        summary_text = summarize_story(sentence+\" \"+previous_image_description)\n",
        "        #generate_sdxl_image(sentence, previous_image_description, output_image_file)\n",
        "        generate_sdxl_image(summary_text, previous_image_description, output_image_file)\n",
        "        img = Image.open(output_image_file)\n",
        "        images.append(img)\n",
        "        story_text.append(sentence)\n",
        "\n",
        "        # Update context with the new sentence\n",
        "        context = sentence\n",
        "\n",
        "        # Update previous image description based on the generated image (for simplicity, this is a placeholder)\n",
        "        previous_image_description = f\"A futuristic scene depicting {sentence[:100]}\"\n",
        "\n",
        "    print (\"==================================================================\" )\n",
        "    stitch_images_and_text(images, story_text, \"final_manga.pdf\")\n",
        "\n",
        "# Example usage:\n",
        "#prompt = \"Two passengers aboard a spaceship traveling to a distant colony planet are awoken from hypersleep decades too early. As they navigate life in isolation, they form a bond and uncover a life-threatening secret that could jeopardize the entire mission.\"\n",
        "prompt = \"A kingdom of monkeys tries to build a city using the resources from the jungle. An elephant army from another elphant kingdom attacks the monkey kingdom.\"\n",
        "create_manga(prompt)"
      ]
    }
  ]
}